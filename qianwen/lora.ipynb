{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb173359",
   "metadata": {},
   "source": [
    "# 安装依赖库\n",
    "\n",
    "- 使用Miniconda创建环境  \n",
    "conda create -n traffic_forecast python=3.10  \n",
    "conda activate traffic_forecast   \n",
    "\n",
    "- 安装核心库  \n",
    "pip install torch transformers datasets peft accelerate pandas numpy swanlab  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb663c7",
   "metadata": {},
   "source": [
    "# 生成模拟交通流量数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8730864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_traffic_data(num_samples=1000, seq_len=24, pred_len=6):\n",
    "    \"\"\"生成模拟交通流量时间序列数据\"\"\"\n",
    "    timestamps = pd.date_range(start=\"2024-01-01\", periods=num_samples+seq_len+pred_len, freq=\"H\")\n",
    "    data = {\n",
    "        \"time\": [],\n",
    "        \"road_id\": [],\n",
    "        \"traffic_flow\": [],\n",
    "        \"prompt\": [],\n",
    "        \"target\": []\n",
    "    }\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # 生成路段ID和基础流量\n",
    "        road_id = np.random.choice([\"A1\", \"B2\", \"C3\"])\n",
    "        base_flow = np.random.randint(50, 200)\n",
    "        \n",
    "        # 生成带周期性的时间序列\n",
    "        historical = base_flow + 20 * np.sin(np.linspace(0, 2*np.pi, seq_len)) + np.random.normal(0, 5, seq_len)\n",
    "        future = base_flow + 20 * np.sin(np.linspace(2*np.pi, 4*np.pi, pred_len)) + np.random.normal(0, 5, pred_len)\n",
    "        \n",
    "        # 构建Prompt\n",
    "        prompt = f\"已知过去{seq_len}小时交通流量为：{historical.tolist()}，预测未来{pred_len}小时流量为：\"\n",
    "        target = \", \".join(map(str, future.round().astype(int)))\n",
    "        \n",
    "        # 填充数据\n",
    "        data[\"time\"].append(timestamps[i:i+seq_len])\n",
    "        data[\"road_id\"].append(road_id)\n",
    "        data[\"traffic_flow\"].append(historical.tolist())\n",
    "        data[\"prompt\"].append(prompt)\n",
    "        data[\"target\"].append(target)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# 生成并保存数据\n",
    "traffic_df = generate_traffic_data()\n",
    "traffic_df.to_csv(\"./data/traffic_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc450546",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bf5a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据格式转换\n",
    "\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "traffic_df = pd.read_csv(\"./data/traffic_dataset.csv\")\n",
    "# Convert the 'time' column to a list of strings\n",
    "traffic_df['time'] = traffic_df['time'].apply(lambda x: [str(t) for t in x])\n",
    "\n",
    "# Create the Dataset\n",
    "dataset = Dataset.from_pandas(traffic_df)\n",
    "dataset = dataset.train_test_split(test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8676b53",
   "metadata": {},
   "source": [
    "# 模型准备与LoRA配置  \n",
    "下载Qwen2-0.5B基座模型  \n",
    "首次下载很慢\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c0cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# login()\n",
    "model_name = \"Qwen/Qwen2-0.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd751c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置LoRA参数\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,                  # 秩大小\n",
    "    lora_alpha=32,        # 缩放因子\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],  # 修改注意力层\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()  # 应显示可训练参数约0.1%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2e009",
   "metadata": {},
   "source": [
    "# 模型微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f242188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理函数\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    texts = [p + t for p, t in zip(examples[\"prompt\"], examples[\"target\"])]\n",
    "    tokenized = tokenizer(\n",
    "        texts,\n",
    "        max_length=128,# 减少序列长度\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb906da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import swanlab\n",
    "# SwanLab可视化配置\n",
    "swanlab.init(project=\"Traffic-Forecast\", experiment_name=\"Qwen2-LoRA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1064f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练参数配置\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=2,# 减少训练轮数\n",
    "    per_device_train_batch_size=2, # 减小批量大小\n",
    "    gradient_accumulation_steps=1, # 禁用梯度累积\n",
    "    learning_rate=5e-4,# 调整学习率\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    logging_steps=200,# 减少日志记录频率\n",
    "    report_to=\"swanlab\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"]\n",
    ")\n",
    "\n",
    "# 开始训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3d5171",
   "metadata": {},
   "source": [
    "# 模型调用与预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ab3a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载微调后的模型\n",
    "from peft import PeftModel\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"qwen/Qwen2-0.5B\")\n",
    "# 自动加载 adapter_config.json，注意目录位置\n",
    "model = PeftModel.from_pretrained(model, \"./results/checkpoint-500\")\n",
    "model = model.merge_and_unload()  # 合并LoRA权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa7695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测函数\n",
    "def predict_traffic(prompt, max_new_tokens=50):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=0.7,\n",
    "        do_sample=False\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# 示例预测\n",
    "test_prompt = \"已知过去24小时交通流量为：[160, 167, 164, 176, 175, 179, 189, 172, 163, 171, 161, 157, 160, 140, 145, 139, 133, 137, 145, 146, 143, 148, 141, 153]，预测未来6小时流量为：\"\n",
    "prediction = predict_traffic(test_prompt)\n",
    "print(prediction)  # 输出形如：\"132, 128, 140, 145, 138, 130\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1563a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "note_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
