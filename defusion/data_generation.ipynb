{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b602416",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (256) must match the size of tensor b (128) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 186\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# 训练5个epoch\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m--> 186\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# --------------------\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# 5. 轨迹生成（采样）\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# --------------------\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 170\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m noisy_traj, noise \u001b[38;5;241m=\u001b[39m forward_diffusion(\n\u001b[1;32m    167\u001b[0m     batch, t, sqrt_alphas_cumprod, sqrt_one_minus_alphas_cumprod)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# 噪声预测\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m pred_noise \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_traj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# 损失计算\u001b[39;00m\n\u001b[1;32m    173\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mmse_loss(pred_noise, noise)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/traffic_forecast/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/traffic_forecast/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[4], line 112\u001b[0m, in \u001b[0;36mTrajectoryDenoiser.forward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# 下采样路径\u001b[39;00m\n\u001b[1;32m    111\u001b[0m h1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown1(x) \u001b[38;5;241m+\u001b[39m t_emb  \u001b[38;5;66;03m# (b, dim, l)\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m h2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt_emb\u001b[49m  \u001b[38;5;66;03m# (b, dim*2, l//2)\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# 中间层\u001b[39;00m\n\u001b[1;32m    115\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmid(h2)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (256) must match the size of tensor b (128) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from einops import rearrange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 随机种子设置\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# --------------------\n",
    "# 1. 轨迹数据模拟与预处理\n",
    "# --------------------\n",
    "class SyntheticTrajectoryDataset(Dataset):\n",
    "    \"\"\"生成正弦波+噪声的模拟轨迹数据\"\"\"\n",
    "    def __init__(self, num_samples=1000, seq_len=50):\n",
    "        self.num_samples = num_samples\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 生成基础正弦轨迹\n",
    "        t = np.linspace(0, 2*np.pi, self.seq_len)\n",
    "        x = np.sin(t) + 0.1 * np.random.randn(self.seq_len)\n",
    "        y = np.cos(t) + 0.1 * np.random.randn(self.seq_len)\n",
    "        \n",
    "        # 合并为 (seq_len, 2) 的轨迹\n",
    "        traj = np.stack([x, y], axis=-1).astype(np.float32)\n",
    "        return torch.from_numpy(traj)\n",
    "\n",
    "# 数据参数\n",
    "SEQ_LEN = 50  # 轨迹长度\n",
    "INPUT_DIM = 2  # (x,y)坐标\n",
    "\n",
    "# 创建数据集\n",
    "dataset = SyntheticTrajectoryDataset(num_samples=1000, seq_len=SEQ_LEN)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# --------------------\n",
    "# 2. 扩散模型核心组件\n",
    "# --------------------\n",
    "class SinusoidalEmbedding(nn.Module):\n",
    "    \"\"\"时间步的位置编码\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        \n",
    "    def forward(self, t):\n",
    "        device = t.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = np.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "class TrajectoryDenoiser(nn.Module):\n",
    "    \"\"\"去噪网络：1D U-Net结构\"\"\"\n",
    "    def __init__(self, input_dim=INPUT_DIM, dim=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 时间嵌入\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalEmbedding(dim),\n",
    "            nn.Linear(dim, dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim * 4, dim))\n",
    "        \n",
    "        # 下采样\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, dim, 3, padding=1),\n",
    "            nn.GroupNorm(4, dim),\n",
    "            nn.GELU())\n",
    "        \n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.Conv1d(dim, dim*2, 3, stride=2, padding=1),  # 长度减半\n",
    "            nn.GroupNorm(8, dim*2),\n",
    "            nn.GELU())\n",
    "        \n",
    "        # 中间层\n",
    "        self.mid = nn.Sequential(\n",
    "            nn.Conv1d(dim*2, dim*2, 3, padding=1),\n",
    "            nn.GroupNorm(8, dim*2),\n",
    "            nn.GELU())\n",
    "        \n",
    "        # 上采样\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(dim*2, dim, 4, stride=2, padding=1),  # 长度恢复\n",
    "            nn.GroupNorm(4, dim),\n",
    "            nn.GELU())\n",
    "        \n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.Conv1d(dim*2, dim, 3, padding=1),\n",
    "            nn.GroupNorm(4, dim),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(dim, input_dim, 1))  # 输出与输入同维度\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        # x: (batch, seq_len, input_dim)\n",
    "        x = rearrange(x, 'b l d -> b d l')  # 转为通道优先\n",
    "        \n",
    "        # 时间嵌入\n",
    "        t_emb = self.time_mlp(t)\n",
    "        t_emb = rearrange(t_emb, 'b d -> b d 1')  # 扩增到与特征图相同维度\n",
    "        \n",
    "        # 下采样路径\n",
    "        h1 = self.down1(x) + t_emb  # (b, dim, l)\n",
    "        h2 = self.down2(h1) + t_emb  # (b, dim*2, l//2)\n",
    "        \n",
    "        # 中间层\n",
    "        h = self.mid(h2)\n",
    "        \n",
    "        # 上采样路径\n",
    "        h = self.up1(h)\n",
    "        h = torch.cat([h, h1], dim=1)  # Skip Connection\n",
    "        h = self.up2(h)\n",
    "        \n",
    "        return rearrange(h, 'b d l -> b l d')\n",
    "\n",
    "# --------------------\n",
    "# 3. 扩散过程工具函数\n",
    "# --------------------\n",
    "def linear_beta_schedule(timesteps):\n",
    "    \"\"\"线性噪声调度\"\"\"\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps)\n",
    "\n",
    "def forward_diffusion(x0, t, sqrt_alphas_cumprod, sqrt_one_minus_alphas_cumprod):\n",
    "    \"\"\"前向扩散过程：q(x_t | x_0)\"\"\"\n",
    "    noise = torch.randn_like(x0)\n",
    "    sqrt_alpha = sqrt_alphas_cumprod[t].reshape(-1, 1, 1)\n",
    "    sqrt_one_minus_alpha = sqrt_one_minus_alphas_cumprod[t].reshape(-1, 1, 1)\n",
    "    return sqrt_alpha * x0 + sqrt_one_minus_alpha * noise, noise\n",
    "\n",
    "# 定义扩散参数\n",
    "TIMESTEPS = 200\n",
    "betas = linear_beta_schedule(TIMESTEPS)\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "\n",
    "# --------------------\n",
    "# 4. 训练循环\n",
    "# --------------------\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"cpu\"\n",
    "model = TrajectoryDenoiser().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        # 随机采样时间步\n",
    "        t = torch.randint(0, TIMESTEPS, (batch.size(0),), device=device)\n",
    "        \n",
    "        # 前向扩散\n",
    "        noisy_traj, noise = forward_diffusion(\n",
    "            batch, t, sqrt_alphas_cumprod, sqrt_one_minus_alphas_cumprod)\n",
    "        \n",
    "        # 噪声预测\n",
    "        pred_noise = model(noisy_traj, t)\n",
    "        \n",
    "        # 损失计算\n",
    "        loss = nn.functional.mse_loss(pred_noise, noise)\n",
    "        \n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# 训练5个epoch\n",
    "for epoch in range(5):\n",
    "    loss = train_epoch()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss:.4f}')\n",
    "\n",
    "# --------------------\n",
    "# 5. 轨迹生成（采样）\n",
    "# --------------------\n",
    "@torch.no_grad()\n",
    "def sample(num_samples=1):\n",
    "    \"\"\"从随机噪声开始逐步去噪\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 初始噪声\n",
    "    x = torch.randn((num_samples, SEQ_LEN, INPUT_DIM), device=device)\n",
    "    \n",
    "    for t in reversed(range(TIMESTEPS)):\n",
    "        t_tensor = torch.full((num_samples,), t, device=device, dtype=torch.long)\n",
    "        pred_noise = model(x, t_tensor)\n",
    "        \n",
    "        alpha_t = alphas[t].reshape(-1, 1, 1)\n",
    "        alpha_cumprod_t = alphas_cumprod[t].reshape(-1, 1, 1)\n",
    "        beta_t = betas[t].reshape(-1, 1, 1)\n",
    "        \n",
    "        if t > 0:\n",
    "            noise = torch.randn_like(x)\n",
    "        else:\n",
    "            noise = torch.zeros_like(x)\n",
    "            \n",
    "        # 逆向扩散步\n",
    "        x = (1 / torch.sqrt(alpha_t)) * (\n",
    "            x - ((1 - alpha_t) / torch.sqrt(1 - alpha_cumprod_t)) * pred_noise\n",
    "        ) + torch.sqrt(beta_t) * noise\n",
    "    \n",
    "    return x.cpu()\n",
    "\n",
    "# 生成5条轨迹并可视化\n",
    "generated = sample(5)\n",
    "for i in range(5):\n",
    "    plt.plot(generated[i, :, 0], generated[i, :, 1], alpha=0.5)\n",
    "plt.title('Generated Trajectories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac86fc43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a544f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3808959e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3adbcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711c924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef38c95d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32544bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd62b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b049445b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e62e3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66116f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic_forecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
